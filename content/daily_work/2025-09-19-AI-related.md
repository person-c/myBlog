---
title: 与AI相关
date: 2025-09-19
---

## AI的问题

自从对话式AI出来以后，我就一直使用AI辅助我的工作与学习。最初，我觉得AI很强大，好像什么都懂，但是随着我的使用，我发现AI的能力是有问题的，即使是现在最顶级的通用大模型，GEMINI 2.5pro, 以及GPT5, 也存在很多问题。

我对AI的机制不太清楚，但是似乎是依据前面的文字，推断下一个哪个文字的概率是最大的(这似乎也解释了为什么即使使用同样的提示词，模型还是会给出不完全一样的回答)。如果是这种机制的话，就算它表现得出来似乎是能够理解自然语言，但是其本质还是没有思考能力的。以前我听到一个什么理论，如果如果一个东西长的像鸭子，叫的也像鸭子，那它就是一个鸭子。这个理论似乎可以套在很多东西上；如果以结果为导向作为评价结果，这句话好像没什么问题，实际上很多问题也的确是以最终结果为导向的。但是用这个理论套在大模型上，真认为大模型具有思考能力，我认为是不太合理的。如果仅仅认为两个东西表现的相似就认为他们是同一个东西，显然太过片面。大模型似乎更像是一个极其强大，对大量信息能够进行搜索的引擎。如果用于训练的数据，某个观点的内容比较多，它似乎更倾向于在一个问题上表现出该观点。当然，我觉得这就是大模型的用处。当你询问它问题时，它可以陈述出现有的所有观点，让我们快速了解已有的知识。但这也是问题所在，在我的使用过程中，有两个问题，我觉得是无法解决的。

一来，无法保证AI输出的结果是正确的观点，而是占大多数的观点。但是大多数的观点，并不一定是正确的。即使你使用各种prompt，严格限制其输出方式，例如对每个观点都说明来源，承认不知道的问题，它还是会犯错。这种东西完全不能避免，很容易不小心陷入它的错误中。（因为我用Gemini 审查我的该网站的博客以及笔记内容，即使我设置了各种prompt限制其输出，它并没有照做——如果认为AI会按你的prompt来做， 那就大错特错了）。这一点似乎可以通过对某个领域的所有知识进行专项训练实现，但是我没有体验过此类模型，也就不评论了。

二来，由于其不具有真正的思考能力，我感觉其不具备能做出开创性工作的能力，它或许可以进行排列组合，但是前人没有提出的观点，它是很难给出，这一点导致其似乎无法用于学术上的工作。

话又说回来，如果AI真能解决上面两个问题，感觉真的会有很多人失业了......

由此，现阶段AI最适合的工作感觉仍然是写代码，因为代码的核查，有其标准的规范。能不能运行，达到效果也是显而易见; 尽管可能代码写的有瑕疵的，但毕竟功能是能达到的，大多数项目对代码质量本身是没有太高要求的，只要能够达到功能就行。或者说，任何能够有规范流程评估AI输出正确的工作都很适合用AI解决，或者未来的工作也会聚焦到AI输出的审查规范的建立之上。

## AI 下的创作

AI 对于很多进行文字创作——博客当然也算，是一个不小的冲击。以博客为例，现如今的很多技术问题，AI 都可以解决，写博客分享似乎已经没有意义，除非是真的很难解决的问题，但我想大多数人遇到问题AI足以应付了。当然，这对我也不算什么问题，因为我本就是将该网站当作笔记本，用于整理我的知识，本意也不是作分享所用——这也是该网站没有评论系统的原因。如果对于普通人还坚持创作的意义，我认为在于语言和意识的边界。单纯的思考很容易陷入原地，而创作则是激发思考一个很好的方式。语言每前进一分，思想便前进一分。通过语言的表达，能使得思想更进一步。

## AI 的时代变革

AI 虽然存在一些问题，但是其好处是显而易见的，对于通用大模型不必多说。工欲善其事必先利其器，通用大模型不仅能提高工作效率，对于教育的变革是深远。谁能拥有一个博学的博士无时无刻解答你的问题呢？对于小学到到本科阶段的学习，我认为AI完全没有任何问题，且其水平超过大部分教师。然而，在专业领域的大模型才是更为强大的存在。以智能驾驶为例，国内正在推动L3的自动驾驶。在可预见的未来，所有车辆都会搭载智能驾驶，或者还会通过网络连接所有车辆的行驶数据，车网协同。这无疑会变革整个交通行业，以后的驾照的考取或许是没有必要的了，交通部门的任务也会改变。


## 使用 AI 的技巧

如果你想让AI 从头开始完成一个项目，或许应该先和它讨论具体的技术路线，最好是一个个小的单位能够组合其整个大的任务。然后根据讨论的路线图，将其拆分成一个个具体的单位让其解决。

如果你想让 AI 对现有的项目进行改进，则可以采用具体的形式验证，让其说出修改的东西，原因，以及参考来源，这有助于进行手动的验证。

当然最重要的是不要盲目相信AI的输出！！！