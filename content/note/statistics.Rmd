---
title: "Health/Economic Statistics"
date: "`{r} Sys.Date()`"
---

## 概率

### 1. 概率的哲学基础：数据生成过程

现代统计分析建立在一个核心的哲学观念上：我们观察到的数据，并非确定性的，而是由一个潜在的、不可观测的随机过程所产生的。这个过程被称为数据生成过程 (Data Generating Process, DGP)。

*   **核心公理:**
    1.  经济系统可视为服从某个概率法则的随机试验。
    2.  任何经济现象 (常以数据形式测度) 都可视为上述随机试验的一个结果。随机试验常被称为“数据生成过程”。

我们能观测到的数据只是一个样本 (随机实验产生的结果)，我们的目标是通过这个样本，去推测那个产生它的、更本质的概率模型。倘若根据该数据有了一个假设的概率模型，我们就需要对概率模型进行参数推断，然后对参数进行检验。

如果一项试验能够在相同条件下重复进行，并且该试验至少有两种可能的结果，但在每一次试验前无法确定哪个结果会实现，则称之为随机试验。换言之，随机试验是无法确切预知结果的一种机制。此处“试验”表示一般意义上的观察或测度的过程，而未必是类似于物理学等自然科学中真正实施的实验。

> 怎么理解相同条件下重复进行呢？我们可以理解为其有蕴含了先后顺序，以及，既然是多次实验，那就是有频率的概念。这里的相同的条件下重复实际就是统计学中的一个重要假设：独立同分布。

### 2. 事件、集合与空间：概率论的语言

为了描述DGP，我们需要一套严谨的语言，这就是集合论。

*   **样本空间 (S):** 随机试验所有可能结果的集合。
*   **基本结果 (Basic Outcome):** 样本空间中的单个、不可再分的元素。
*   **事件 (A):** 样本空间的一个子集，代表我们感兴趣的某种结果。

实施一次实验仅会得到样本空间中的一个 (且仅仅一个) 基本结果，而当我们讨论某个事件 A 发生的时候，我们指的是属于 A 的某个基本结果出现了。

**事件 (集合) 的运算与法则—实际是基本结果的重叠情况。**

*   **交集 (Intersection, $A \cap B$):** 事件 A 与事件 B 同时发生，指样本空间 S 中同时属于 A 和 B 的所有基本结果的集合。
*   **互斥 (Mutually Exclusive):** 若 $A \cap B = \emptyset$，则称事件 A 和 B 互斥。它们不能同时发生。
*   **差 (Difference, $A - B$):** 事件 A 发生而事件 B 不发生，即 $A \cap B^c$。
*   **并集 (Union, $A \cup B$):** 事件 A 或事件 B 发生，指代样本空间中属于 A 或者 B 的所有基本结果的集合。
*   **完全穷尽 (Collective Exhaustiveness):** $\bigcup_{i} A_i = S$
*   **补集 (Complement, $A^c$):** 事件 A 不发生。

完全穷尽且互斥的事件集构成了样本空间 S 的一个分割 (partition)；完全穷尽且互斥事件的集合可视为正交基的完备集，可表示样本空间 S 中的任意事件 B，而 $B \cap A_i$ 代表事件 B 在正交基 $A_i$ 上的投影。

任何一个事件 B 都可以被这组基“表示”出来，其在每个基 $A_i$ 上的投影 (Projection) 就是 $B \cap A_i$。因此，事件 B 可以被唯一地分解为： $B = (B \cap A_1) \cup (B \cap A_2) \cup ... \cup (B \cap A_n)$ 这个分解是理解全概率公式的几何直觉。

*   **集合运算法则:**
    *   交换律: $A \cup B = B \cup A$; $A \cap B = B \cap A$
    *   结合律: $(A \cup B) \cup C = A \cup (B \cup C)$; $(A \cap B) \cap C = A \cap (B \cap C)$
    *   分配律: $B \cap (\bigcup_{i} A_i) = \bigcup_{i} (B \cap A_i)$; $B \cup (\bigcap_{i} A_i) = \bigcap_{i} (B \cup A_i)$
    *   德摩根律: $(\bigcup_{i} A_i)^c = \bigcap_{i} A_i^c$; $(\bigcap_{i} A_i)^c = \bigcup_{i} A_i^c$

> 分配律从右侧到左侧总是容易忘记，可以将运算符号一并作为公因子并提取出来例如 A∩ 或者 A∪; De Morgan’s laws 是上标运算，内部符号反号。

### 3. 概率公理与概率空间

概率函数是从事件到实数的映射，是定义在事件上的函数 (事件域)，其定义域为 $\sigma$-代数 ($\sigma$-algebra)。$\sigma$-代数 F 是样本空间 S 的一些子集组成的集合，且满足以下三个条件：

1.  **非空:** $S \in F$ (样本空间本身是一个事件)。
2.  **对补集封闭:** 若 $A \in F$，则其补集 $A^c$ 也必须在 F 中。
3.  **对可数并集封闭:** 若有一系列事件 $A_1, A_2, ... \in F$，则它们的并集 $\bigcup_{i} A_i$ 也必须在 F 中。

由此三条可以推导出 $\emptyset \in F$ 以及对可数交集封闭。(S, F) 则称为可测空间。

*参考来源: Casella, G., & Berger, R. L. (2002). Statistical Inference. Duxbury Press. Section 1.2.*

概率是赋予事件的一个数值，用以衡量其发生可能性的大小。它被严格定义在一个概率空间 (S, F, P) 上，其中：

*   **S:** 样本空间。
*   **F:** 事件域 ($\sigma$-algebra)，一个包含了我们所有感兴趣事件的集合，且对补、可数并、可数交运算封闭。
*   **P:** 概率测度，一个满足以下三条公理的函数：
    1.  公理1 (非负性): 对任何事件 $A \in F$, 有 $P(A) \ge 0$。
    2.  公理2 (规范性): $P(S) = 1$。
    3.  公理3 (可数可加性): 对于一系列互斥事件 $A_1, A_2, ... \in F$, 有 $P(\bigcup_{i} A_i) = \sum_{i} P(A_i)$。

*   **基本推论:**
    *   $P(\emptyset) = 0$
    *   $P(A^c) = 1 - P(A)$
    *   若 $A \subseteq B$, 则 $P(A) \le P(B)$
    *   加法法则: $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
    *   全概率公式: $P(A) = \sum_{i} P(A \cap A_i)$ (事件序列 $A_i \in B, i = 1, 2, ...$ 互斥且完全穷尽)
    *   布尔不等式: $P(\bigcup_{i} A_i) \le \sum_{i} P(A_i)$

> 这些推论可以通过 S 的分解以及集合互斥的关系来证明。

**对概率有两种理解:**

*   相同条件下重复某一实验，同类事件发生的相对频率，某一结果的概率是大量重复下，该结果“相对频率”的极限 (独立同分布假设下)。
*   贝叶斯学派的主观法，将概率视为某一事件发生的主观可能性。

### 4. 计数：从排列到组合的逻辑

当样本空间中的基本结果等可能时，概率计算简化为计数问题：$P(A) = |A| / |S|$。

*   **计数基本定理 (乘法原理):** 若一项任务分 k 步完成，第 i 步有 $n_i$ 种方法，则总方法数为 $n_1 \times n_2 \times ... \times n_k$。
*   **排列 (Permutation, $P^n_x$):** 关注的是“选择并排序”。从 n 个元素中选出 x 个，并为它们排定座次。
    $P^n_x = n(n-1)...(n-x+1) = \frac{n!}{(n-x)!}$
*   **组合 (Combination, $C^n_x$):** 关注的仅仅是“选择”，不关心顺序。

**逻辑联系:** 任何一个排列任务，都可以分解为两步：1. 先从 n 个元素中“组合”出 x 个 ($C^n_x$ 种方法)。2. 再将这 x 个元素进行全排列 ($x!$ 种方法)。

根据乘法原理，我们得到：$P^n_x = C^n_x \times x!$。因此，组合的公式可以由排列导出，这体现了两者内在的逻辑关系：$C^n_x = \frac{P^n_x}{x!} = \frac{n!}{x!(n-x)!}$

*   **四种基本抽样方式:**
    1.  有排序，不放回 (排列): $P^n_r = \frac{n!}{(n-r)!}$
    2.  无排序，不放回 (组合): $C^n_r = \frac{n!}{r!(n-r)!}$
    3.  有排序，放回: $n^r$
    4.  无排序，放回: $C^{n+r-1}_r = \frac{(n+r-1)!}{r!(n-1)!}$

### 5. 条件概率与独立性：信息与关联

*   **条件概率 ($P(A|B)$):** 度量了信息的价值。它告诉我们，在获得“事件 B 发生”这一信息后，我们对事件 A 发生可能性的判断应如何更新。

它描述的是一种预测关系 (predictive relationship)，但不等于因果关系 (causal relationship)。这是计量经济学中一个至关重要的区别。

$P(A|B) = \frac{P(A \cap B)}{P(B)}$, (假设 $P(B) > 0$)

我们有如下的计算事件 A 和 B 的联合概率的乘法法则：

$P(A \cap B) = P(A|B)P(B) = P(B|A)P(A)$

其有如下推广：

对于多个事件 $A_1, A_2, ..., A_n$，联合概率可以递归地计算：

$P(A_1 \cap A_2 \cap ... \cap A_n) = P(A_1)P(A_2|A_1)P(A_3|A_1 \cap A_2) ... P(A_n|A_1 \cap A_2 \cap ... \cap A_{n-1})$

> 事实上，有 n! 种不同的条件序列可以表示联合概率 $P(\bigcap_{i} A_i)$，但是在时间序列分析中，若 i 表示时间，则事件 $A_i$ 基于前 $i-1$ 个事件的条件概率 $P(A_i|A_1 \cap A_2 \cap ... \cap A_{i-1})$ 是最自然的，有呵护逻辑的解释，即以 $i-1$ 期可获取的历史信息预测下一期事件 $A_i$ 发生的概率。

*   **独立性 (Independence):** 描述了事件之间完全没有关联的特殊情况。如果信息 B 对预测 A 毫无帮助，即 $P(A|B) = P(A)$，则称 A, B 独立。其标准定义为：
    $P(A \cap B) = P(A)P(B)$

*   **多个事件的独立性:** 对于事件 $A_1, ..., A_k$，它们相互独立，当且仅当其任意子集的联合概率都等于各自概率的乘积。例如，对于3个事件，需要满足4个条件：
    *   $P(A_1 \cap A_2) = P(A_1)P(A_2)$
    *   $P(A_1 \cap A_3) = P(A_1)P(A_3)$
    *   $P(A_2 \cap A_3) = P(A_2)P(A_3)$
    *   $P(A_1 \cap A_2 \cap A_3) = P(A_1)P(A_2)P(A_3)$

*   **独立 vs. 互斥:** 如果两个事件有正概率，那么它们不可能既独立又互斥。互斥意味着一个发生另一个必不发生 (极度相关)，而独立意味着两者发生与否互不相干。

### 6. 全概率公式与贝叶斯定理：推断的核心

*   **全概率公式:** 正是前述“事件投影”思想的概率体现。如果 {$B_i$} 是样本空间的一个分割 (一组完备正交基)，那么任何事件 A 的总概率等于其在各个基上的投影的概率之和—— $P(A|B_i)$ 是其在基 $B_i$ 上的投影概率，而 $P(B_i)$ 是基 $B_i$ 的权重。
    $P(A) = \sum_{i} P(A \cap B_i) = \sum_{i} P(A|B_i)P(B_i)$

*   **贝叶斯定理:** 是统计推断的灵魂，它将“执果索因”的过程数学化。
    $P(B_i|A) = \frac{P(A \cap B_i)}{P(A)} = \frac{P(A|B_i)P(B_i)}{P(A)} = \frac{P(A|B_i)P(B_i)}{\sum_{j} P(A|B_j)P(B_j)}$
    *   **$P(B_i)$: 先验概率 (Prior)**，在看到证据 A 之前，我们对原因 $B_i$ 的信念。
    *   **$P(A|B_i)$: 似然 (Likelihood)**，在原因 $B_i$ 成立的条件下，观察到证据 A 的可能性。
    *   **$P(B_i|A)$: 后验概率 (Posterior)**，在看到证据 A 之后，我们对原因 $B_i$ 更新后的信念。

> 贝叶斯更新过程的直观理解：这是一个信念迭代更新的循环。我们从一个初始的“先验”信念出发，当“新证据”出现时，我们利用“似然”来评估证据在不同假设下的支持度，最终得到一个融合了先验知识和新证据的、更可靠的“后验”信念——我们已知的条件是先验概率，以及似然概率；当结果 A 出现后就会更新我们的先验概率 $B_i$。


# 统计描述

首先了解数据的频数分布,选用合适的集中以及离散趋势描述数据。

- 观察单位。被观察或测量对象的最基本单位。
- 变量类型。数值变量/分类变量——有序,无序。
- 同质(homogeneity)与变异(variation)。研究对象具有的相同的状况或属性等共性称同质。对于同质的各观察单位,其某变量之间的差异,称为变异。
- 总体(population)。总体是根据研究目的确定的同质的观察单位全体,确切地说,是同质的所有观察单位某种变量值的集合。
- 样本(sample)。样本是指总体中的一部分观察单位的某项变量值的集合,这一部分必须是对总体具有代表性的。
- 误差(error)。包括系统误差(systermatic error) 以及 随机测量误差(error of randon measurement)和 抽样误差(sampling error)。


## 数值变量

频数表的编制：

1. 求全距。
2. 确定组数, $range / n$ 取整 $[x, x + n)$。
3. 列表划计。

-   对称或者正态分布数据选用算术均值描述其均值,方差/标准差/变异系数描述其离散程度。


> 标准差的单位与原数据相同,方差的单位是原始数据单位的平方。变异系数是一个无量纲的相对数，所以可以用于不同尺度, 不同单位均值相差较大的数据直接相互比较。 方差/标准差/变异系数的计算都依赖于均值的计算。
> 
> 1. $CV = \frac{S}{\bar{X}} \cdot 100\%$

-   对数正态分布数据, 例如抗体的几何滴度,细菌计数等,选用几何均值描述其分布,全距/四分位数描述其离散趋势。

1. $G  = (\prod{X})^{\frac{1}{n}} \rightarrow 10^{\frac{\sum{lgX}}{n}}$
  
-   任意其它分布选用中位数,全距/四分位数

1. $M = L + \frac{i}{f_X}(n \cdot X\% - \sum{f_L})$

## 分类变量

分类变量数据主要依赖于各种相对数描述,包括比例(proportion),速率(rate), 相对比(ratio). 其中rate主要涉及到时间的概念,需要注意孕妇死亡率等是相对比指标。

数据的标准化法：

1. 直接化法,按总人口统一人口数,等价于对每组分层数据的率求均值-即每组中每个分层的权重都一致。
2.  间接法, 依据标准化率计算不同组的理论值,实际值与理论值之比即得到标准化死亡比(standard mortality ration, SMR), 进而求得当地的标准化死亡率 $p' = p \cdot SMR$.

动态数列：定基/环比,变化/增长(-1),平均发展速度/平均变化速度(-1)。


# 实验设计与调查研究

## 实验设计

医学实验的特点：最终对象是人

1. 人具有生物学和社会学属性。
2. 人的个体变异性较大,实验单位的一致性较差,观察结果的离散程度较大。
3. 一般不允许在人体上直接实验,需先进行动物实验。


医学实验设计要素：

1. 处理因素。
2. 受试对象。受试对象要求对处理因素敏感,以及反应稳定。
3. 实验效应。


实验设计的基本原则：

1. 对照。
2. 随机化。包括抽取随机,分配随机,相同机会接受不同的实验顺序三层含义。
3. 重复。
4. 知情同意。

常用的设计方案包括完全随机化,区组化设计,析因设计以及被试内设计。被试内设计通过将个体的差异转化为重复测量的差异,而减少了误差。


## 调查研究

调查研究最大特点在于其只能被动观察,以及需要更大样本进而有更大的误差。

调查设计的原则需要完整,可行,经济,时效。

可行性分析可以通过逻辑分析,或者经验判断,或者试调查。

抽样的基本程序包括界定研究总体和调查总体,设计抽样方法,编制抽样框架,抽取样本,评估样本。

调查技术包括问卷,电话,访谈,观察法以及敏感问题调查技术-随机化应答技术。

非抽样误差包括抽样框误差,无回答误差,以及计量误差。

非抽样误差的估计有以下方法：

1. 调查质量控制措施的完善程度和落实情况。
2. 调查的应答率。
3. 比较不同来源的资料。
4. 进行抽样复查。
   
# Parametric Statistics

## Sampling Distribution for $\chi^2, F, t$

首先给出各分布构造的定义：

- 若 $\left\{  X_i \right\}_{i=1}^n$ 独立同分布于 $N(0, 1)$, 那么 $\sum{X_i^2} \sim \chi^2(n)$, 其 $E(\chi^2) = n, Var(\chi^2) = 2n$.
- 若有 $\chi^2_1(m)$, $\chi^2_2(n)$, 那么 $\frac{\frac{\chi_1^2}{m}}{\frac{\chi_2^2}{n}} \sim F(m, n).$
- 若有 $X \sim \mathcal{N}(0, 1)$, 以及 $\chi^2(n)$, 那么 $\frac{X}{\sqrt{\frac{\chi^2(n)}{n}}} \sim t(n)$


::: {#thm-th1}

设 $\left\{ x_{i} \right\}_{i=1}^{n}$ 是来自正态总体 $\mathcal{N}(\mu, \sigma^2)$ 的样本,其样本均值和方差分别为:

1. $\bar{x} = \frac{1}{n}\sum{x_i}$
2. $s^2 = \frac{1}{n-1}\sum{(x - \bar{x})^2}$

则：

1. $\bar{x} \sim \mathcal{N}(\mu, \sigma^2/n)$
2. $\frac{(n-1)s^2}{\sigma^2} \sim \chi^2_{(n-1)}$
3. $\bar{x}, s^2$ 相互独立

> 1. 这里描述的是正态总体样本的均值服从于正态分布,而其样本的方差 $s$ 服从于卡方分布。
> 2. 注意 $s$ 是样本的方差,而不是属于样本均值正态分布的方差,样本均值的正态分布的方差为 $\frac{\sigma^2}{n}$
:::


::: {#thm-th2}

设 $\left\{ x_i \right\}_{i=1}^m$ 是来自 $\mathcal{N}(\mu_1, \sigma_1)$ 的样本, $\left\{ y_i \right\}_{i=1}^n$ 是来自 $\mathcal{N}(\mu_2, \sigma_2)$ 的样本,那么：

1. $\bar{x} = \frac{1}{m}\sum{x}, \bar{y} = \frac{1}{n}\sum{y}$
2. $s_x^2 = \frac{1}{m-1}\sum{(x - \bar{x})^2}, s_y^2 = \frac{1}{n -1}\sum{(y - \bar{y})^2}$

则：

1. $\frac{s_x^2/\sigma_1^2}{s_y^2/\sigma_2^2} \sim F(m - 1, n - 1)$

证明：

1. $\frac{(m - 1)s_x^2}{\sigma^1} \sim \chi^2(m - 1), \frac{(n - 1)s_y^2}{\sigma_2^2} \sim \chi^2(n-1)$
2. $\frac{(1.1)/(m - 1)}{(1.2)/(n-1)} \sim F(m - 1, n - 1)$
:::



::: {#thm-th3}

设 $\left\{ x_{i} \right\}_{i=1}^{n}$ 是来自正态总体 $\mathcal{N}(\mu, \sigma^2)$ 的样本,其样本均值和方差分别为:

1. $\bar{x} = \frac{1}{n}\sum{x_i}$
2. $s^2 = \frac{1}{n-1}\sum{(x - \bar{x})^2}$

则：

1. $\frac{\bar{x} - \mu}{\sigma \cdot \sqrt{\frac{1}{n}}} \sim t(n-1)$

证明：


1. $\frac{\bar{x} - \mu}{\sigma \cdot \sqrt{\frac{1}{n}}} \sim \mathcal{N}(0, 1)$ 
2. $\frac{(n - 1)s^2}{\sigma^2} \sim \chi^2(n - 1)$ 
3. $\frac{(1)}{\sqrt{(2)/(n - 1)}} \rightarrow  \frac{\bar{x} - \mu}{s\cdot \sqrt{\frac{1}{n}}} \sim t(n-1)$
  
:::


::: {#thm-th4}

设 $\left\{ x_i \right\}_{i=1}^m$ 是来自 $\mathcal{N}(\mu_1, \sigma_1^2)$ 的样本, $\left\{ y_i \right\}_{i=1}^n$ 是来自 $\mathcal{N}(\mu_2, \sigma_2^2)$ 的样本,那么：

1. $\bar{x} = \frac{1}{m}\sum{x}, \bar{y} = \frac{1}{n}\sum{y}$
2. $s_x^2 = \frac{1}{m-1}\sum{(x - \bar{x})^2}, s_y^2 = \frac{1}{n -1}\sum{(y - \bar{y})^2}$

设 $\sigma_1^2 = \sigma_2^2 = \sigma^2$, 则：

1. $\frac{(\bar{x} - \bar{y}) - (\mu_1 - \mu_2)}{s_p \cdot \sqrt{\frac{1}{m} + \frac{1}{n}}} \sim t(m + n - 2), \text{where } s_p^2 = \frac{(m - 1)s_x^2 + (n - 1)s_y^2}{m + n - 2}$

证明：

由两样本独立且正态分布：

1. $(\bar{x} - \bar{y}) \sim \mathcal{N}(\mu_1 - \mu_1, (\frac{1}{m} + \frac{1}{n})\sigma^2)$
2. $\frac{(\bar{x} - \bar{y}) - (\mu_1 - \mu_2)}{\sigma \cdot \sqrt{\frac{1}{m} + \frac{1}{n}}} \sim \mathcal{N}(0, 1)$
:::

由卡方变量可加性：

1. $\frac{(m - 1)s_x^2}{\sigma_1^2} \sim \chi^2(m - 1), \frac{(n-1)s_y^2}{\sigma_2^2} \sim \chi^2(n-1)$
2. $\frac{(m - 1)s_x^2}{\sigma^2} + \frac{(n-1)s_y^2}{\sigma^2} \sim \chi^2(m + n - 2)\rightarrow \frac{s_p^2 \cdot (m + n - 2)}{\sigma^2} \sim \chi^2(m + n - 2)$


## $t/z \text{ Test }$

### Assumptions and Its Application Case


From [wikipedia](https://en.wikipedia.org/wiki/Student%27s_t-test#Assumptions):

> For exactness, the t-test and Z-test require normality of the sample means, and the t-test additionally requires that the sample variance follows a scaled $\chi^2$ distribution, and that the sample mean and sample variance be statistically independent. Normality of the individual data values is not required if these conditions are met. By the central limit theorem, sample means of moderately large samples are often well-approximated by a normal distribution even if the data are not normally distributed. For non-normal data, the distribution of the sample variance may deviate substantially from a $\chi^2$ distribution.
>
> However, if the sample size is large, Slutsky's theorem implies that the distribution of the sample variance has little effect on the distribution of the test statistic. That is as sample size
>
> -   ${\displaystyle {\sqrt {n}}({\bar {X}}-\mu )\xrightarrow {d} N\left(0,\sigma ^{2}\right)}$ as per the Central limit theorem.
>
> -   ${\displaystyle s^{2}\xrightarrow {p} \sigma ^{2}}$ as per the Law of large numbers.
>
> -   ${\displaystyle \therefore {\frac {{\sqrt {n}}({\bar {X}}-\mu )}{s}}\xrightarrow {d} N(0,1)}$
>

我们知道 $t$ 分布的构造定义如下：

$$
\frac{X}{\sqrt{\chi_{(n - 1)}/{(n-1)}}}, \text{where} X \sim \mathcal{N}(0, 1)
$$

从 $t$ 的构造中可知,我们需要一个 $X \sim \mathcal{N}(0, 1)$ 的正态变量；而在大样本情况下, 依据中心极限定理,样本均值总是符合正态分布。 进一步地,依据大数定理, $s^2 \approx \sigma^2$ , 所以直接用 $s$ 替代 $\sigma$ 可以进行 $z$ 检验。实际上,在大样本下如下公式总是成立的：

1. $\bar{x} \sim \mathcal{N}(\mu, \frac{1}{n}\sigma^2) \rightarrow \text{Central Limit Theory}$

> Specially, 设二项分布 $X \sim B(n, p)$:
> 
> 则：
> 
> 1. $\bar{x} \sim \mathcal{N}(np, np(1-p)), \text{When} x \rightarrow \infty$
>
> 2. $\hat{p} \sim \mathcal{N}(p, \frac{1}{n}p(1-p))$
> 对于二项分布而言,其总体的期望以及方差实际上描述的就是多次独立的伯努利实验的期望与方差。

 而大样本下 $t$ 分布近似于 $z$ 分布。所以 $t$ 分布可以应用于小样本下的正态总体,以及大样本下的任意总体的均值的检验。

 在应用 $t$ 检验时,我们往往只有一个或两个样本的均值与方差,计算的关键就在于如何利用样本方差计算得到均值分布的方差。

### One Smple $t$-Test

1. $\bar{x} \sim \mathcal{N}(\mu, \frac{1}{n}\sigma^2)  \rightarrow \frac{\bar{x} - \mu}{\sigma \cdot \sqrt{\frac{1}{n}}} \sim \mathcal{N}(0, 1)$
2. $\frac{\bar{x} - \mu}{s \cdot \sqrt{\frac{1}{n}}} \sim t(n-1)$

应用条件：

1. 小样本正态分布,大样本。

### Paired $t$-Test

$t(\upsilon) = \frac{\left|\bar{d} - 0\right|}{s_{\bar{d}}} = \frac{\bar{d}}{s_{\bar{d}}}, \text{ where } \upsilon = \text{对子数} - 1, s_{\bar{d}} = s_d \cdot \sqrt{\frac{1}{n}}$

证明：

1. $\frac{\bar{d} - \mu_d}{\sigma_d \cdot \sqrt{\frac{1}{n}}} \sim \mathcal{N}(0, 1)$

应用条件：

1. 小样本下, $d$ 服从于正态分布。
2. 大样本。

### Independent Two Sample $t$-Test

两个总体的比较需要对方差齐性进行检验：

1. $F = \frac{S_1^2}{S_2^2}, \upsilon_1 = n_1 - 1, \upsilon_2 = n_2 - 1$, 其中 $S_1^2$ 是比较大的那个。

When $\sigma_1 = \sigma_2 = \sigma$:

1. $\frac{(\bar{x} - \bar{y}) - (\mu_1 - \mu_2)}{s_p \cdot \sqrt{\frac{1}{m} + \frac{1}{n}}} \sim t(m + n - 2), \text{where } s_p^2= \frac{(m-1)s_x^2 + (n - 1)s_y^2}{m + n - 2}$

When $\sigma_1 \neq \sigma_2 \text{ or Unknown for it} \rightarrow \text{ Welch's t-Test}$:

1. $t^\prime(\upsilon) = \frac{\bar{x} - \bar{y}}{\sqrt{\frac{s_1^2}{m} + \frac{s_2^2}{n}}}$

通过 $\text{Satterhwaite}$ 法,对自由度进行校正

1. $\upsilon = \frac{(\frac{s_1^2}{m} + \frac{s_2^2}{n})^2}{\frac{s_1^4}{m^2}/(m-1) + \frac{s_2^4}{n^2}/(n-1)}$


## $B(n, p)/Po(\lambda) \text{ Test}$

设事件 $A$ 发生的概率为 $\pi$, 那么在 $n$ 次伯努利试验中,该事件发生次数 $k$:

1. $P(k) = \binom{n}{k} \pi^k \cdot(1-\pi)^{n - k}, \text{where } \binom{n}{k} = \frac{n!}{k!\cdot(n-k)!}$

其中 $\binom{n}{k}$ 正好是 牛顿二项展开式 $\left[ (1 - \pi) + \pi \right]^n$ 第 $k + 1$ 项。

设 $X \sim B(n, \pi)$, 则：

1. $X \sim \mathcal{N}(n\pi, n\pi(1 - \pi), \text{When } n\pi > 5 \text{ and } n(1 - \pi) > 5$
2. $Z = \frac{X - n\pi}{\sqrt{n\pi{(1 - \pi)}}} = \frac{p - \pi}{\sqrt{\pi(1 - \pi)/n}} \sim \mathcal{N}(0, 1)$
3. $p \sim \mathcal{N}(\pi, \frac{\pi(1-\pi)}{n})$


当 $\pi$ 特别小时,设 $\lambda = n\pi$, 则当 $n \rightarrow \infty$ :

1. $P(X) = \frac{e^{-\lambda}\lambda^X}{X!}$

> 1. $n$ 足够大,以至于每 $\frac{1}{n}$ 中只有发生与不发生两种情况。
> 
> 2. 每一份 $\frac{1}{n}$ 中其概率都为 $\frac{\pi}{n}$
>
> 3. 每一份中之间是相互独立的。
>

则 $X \sim Po(\lambda)$

1. $X \sim \mathcal{N}(\lambda, \lambda) \rightarrow \frac{X - \lambda}{\sqrt{\lambda}} \sim \mathcal{N}(0, 1),\text{When } \lambda > 20$
2. $Z = \frac{X_1/n_1 - X_2/n_2}{\sqrt{X_1/n_1^2 + X_2/n_2^2}}$

泊松分布最大的特征就是其均值与方差都等于 $\lambda$, 我们常用这一点来判断一个分布是否属于泊松分布。此外,泊松分布具有可加性。考虑 $X_1 \sim Po(\lambda_1), X_2 \sim Po(\lambda_2)$, 且互相独立：

1. $X_1 + X_2 \sim Po(\lambda_1 + \lambda_2)$

## Analysis of Variance

### One Way ANOVA

该假设的原理如下：

>If the group means are drawn from populations with the same mean values, the variance between the group means should be lower than the variance of the samples, following the central limit theorem - [wikipedia](https://en.wikipedia.org/wiki/One-way_analysis_of_variance)


其需要满足的假设如下：

1. 正态总体
2. 方差齐性
3. 样本独立性

> Tiku (1971) found that "the non-normal theory power of F is found to differ from the normal theory power by a correction term which decreases sharply with increasing sample size." The problem of non-normality, especially in large samples, is far less serious than popular articles would suggest - [wikipedia](https://en.wikipedia.org/wiki/One-way_analysis_of_variance)


1. $Y_{ij} - \bar{Y} = (Y_{ij} - Y_i) + (Y_i - \bar{Y})$
2. $\sum_{i=1}^a\sum_{j=1}^{n_i} \left( Y_{ij} - \bar{Y} \right)^2 = \sum_{i=1}^a\sum_{j=1}^{n_i} \left(Y_{ij} - Y_i \right)^2 + \sum_{i=1}^a n_i\left( {Y_i - \bar{Y}} \right)^2$
3. $F = \frac{\sum_{i=1}^a n_i\left( \bar{Y_i} - \bar{Y} \right)^2 \bigg/ (a - 1)}{\sum_{i=1}^a\sum_{j=1}^{n_i} \left(Y_{ij} - \bar{Y_i} \right)^2 \bigg/ (N - a)} \sim F_{(a-1, N-a)})$


从公式的推导之中可以看到,其核心在于对变异(SS, sum of squares)的分解 $SS_{\text{total}} = SS_{\text{within group}} + SS_{\text{between group}}$。方差分析需要进行Levene's方差齐性检验,该检验实际上是对每个值减去该组均值的差异做单因素方差分析：

1. $Z_{ij} = |Y_{ij} - \bar{Y_i}|$
2. $L = \frac{\frac{\sum_{i=1}^a n_i\left( \bar{Z_i} - \bar{Z} \right)^2}{a - 1}}{\frac{\sum_{i=1}^a\sum_{j=1}^{n_i} \left(Z_{ij} - \bar{Z_i} \right)^2}{N - a}} \sim F_{(a-1, N-a)}$ .


### Special Two Way ANOVA - Random Block Design

当观测变量有多个时,进行方差分析,不仅要考虑每个变量的观测值的影响,还需要考虑变量之间的交互作用对观测值的影响。而随机区块设计通过分组以后再进行随机化,使得我们可以不考虑两者的交互作用,只考虑两个变量分别对结果的影响；

1. $Y_{ij} - \bar{Y} = (\bar{Y_i} - \bar{Y}) + (\bar{Y_j} - \bar{Y}) + (Y_{ij} - \bar{Y_i} - \bar{Y_j} + \bar{Y})$

从上面的公式可以看出,随机区组设计将变异分为两个变量来源(区组,实验因素),以及个体本身的误差,其中误差项的自由度为 $(n-1)(a - 1).$


对于混杂因素的控制还有将线性回归与方差分析结合起来的协方差分析,其对个体值的分解如下：

1. $Y_{ij} = \bar{Y_i} + b(\bar{X}_{ij} - \bar{X}) + e_{ij}$

其中 $X$ 是混杂因素。


## Mutiple Hypothesis Test

方差分析对各处理组均数是否相等总的检验,在 $H_0$ 被拒绝以后,需要确定究竟是哪些处理组之间存在差异,此时需要进行均数之间的多重比较,这就涉及到累计I型错误率。

当 $a$ 个处理组均数需要两两比较时候,共需要比较 $c = a!/[2!(a-2)!]$。 设每次检验的检验水准为 $\alpha$ ,累积I型错误概率为 $'\alpha$, 则

1. $'\alpha = 1 - (1 - \alpha)^c$

### $q$ -Test/student-Newman-Keuls

$q \text{Test}$ 用于任意两组之间的相互比较,SNK法的检验效能介于Bonferroni和Tukey法之间的；当比较均值的组数较多时,Tukey法更有效,组数较少时,ferroni法更有效。

其计算过程如下：

1. 将各组的平均值按由小到大的顺序排列。
2. 计算两个平均之间的差值以及组间跨度 $r$


则 $q$ 统计量：

1. $q = \frac{{\bar{Y_i} - \bar{Y_h}}}{\sqrt{\frac{MS_{within \: group}}{2}(\frac{1}{n_i} + \frac{1}{n_h})}}$

其中 $\bar{Y_i}, \bar{Y_h}$ 及 $n_i, n_h$ 分别是两个比较组的均数以及样本例数, $MS_{\text{within group}}$ 为进行方差分析得到的组内均方。



### Dunnett- $t$ Test

$t_D$ 统计量处理组与对照组的比较,该统计量的计算如下：

1. $t_D = \frac{\bar{Y_i} - \bar{Y_c}}{\sqrt{MS_{within \: group} \times (\frac{1}{n}_i + \frac{1}{n_c})}}$

其中 $\bar{Y_i}, \bar{Y_c}$ 及 $n_i, n_c$ 分别是实验组与对照组的均数以及样本例数, $MS_\text{within group}$ 为进行方差分析得到的组内均方。



# Non-parametric Statistics


## $\chi^2 \text{ Test}$

卡方检验用于观测变量为无序分类变量时, 用于检验零假设下观测频数与理论频数(将所有组合并为一个组计算出的每个结局的频率分布,然后乘以原组的频数)之间偏离如此大范围的概率(如果观测变量为有序的分类变量,则该使用秩相关的检验)。该方法应用的条件如下：

> 1. 不宜有 $\frac{1}{5}$ 的格子数的理论频数小于 $5$, 或有一个格子的理论频数小于1,否则将导致分析的偏性。可采取扩大样本含量,或者合并或者删除不符合条件的数据。后两者会损失信息,样本随机性,可能会影响推断结论。
> 
> 2. 多个样本率(即多分组,观测变量为无序的二分类变量)的比较,显著的差异只能推断出这几组之间有总体的差异,但是不能推出其中两者之间是否存在差异。此时可将不同组的数据两两组合重新进行卡方检验进行推断,此时的检验水准的计算公式为 $\frac{\alpha}{k(k-1)/2 + 1}$

考虑一个 $R \cdot  C$ 的列联表

1. $\chi^2 = \sum\frac{(O - E)^2}{E}, \text{where} E_{rc}= \frac{n_{r}n_{c}}{n} \rightarrow \chi^2 = n(\sum\frac{O^2}{n_{r}n_{c}} - 1)$

> 1. 如果为单变量,按样本分组；如果观测变量是无序二分类的,则是率的比较；如果观测变量为无序多分类,则为频数分布的比较。
> 2. 如果为两个无序的观测变量,则为两个观测变量关联性检验,此时还需要进一步计算关联系数 $C \text{ (contigency coefficient)} = \sqrt{\frac{\chi^2}{n + \chi^2}}$


对于称为四格表的资料,即 $2*2$ 的列联表,其计算的简化形式为：

1. $\chi^2 = \frac{(ad - bc)^2n}{(a+b)(c+d)(a+c)(b+d)}$

特别地, 当理论频数存在 $1 < E < 5$ 时有如下的 Yate correction for continuity：

1. $\chi^2 = \sum\frac{(\mid O - E \mid - 0.5)^2}{E} = \frac{(|ad - bc| - \frac{n}{2})^2n}{(a+b)(c+d)(a+c)(b+d)}$ 

> 实际上Pearson卡方值是正态总体中一种连续性的变量,四格表资料的卡方值为不连续的值,卡方分布仅仅是对表格资料的统计量分布的近似分布。 当四格表中有小于5的期望值时,其卡方值偏大,减去 $0.5$ 进行Yate 的连续性校正。

若 $n \le 40 \text{ or } E \le 1$ 则采用Fisher确切概率法。

1. $P = \frac{\binom{a + c}{a}\binom{b + d}{b}}{\binom{n}{a + b}} = \frac{(a+b)!(a+c)!(b+c)!(b+d)!}{a!b!c!d!n!}$

> 实际上fisher确切概率法给出了 $R * C$ 列联表的确切概率,可以用于任意情况的检验；但是这里给出的是某一种情况的概率,为了求得比当前情况都更为极端的差值,在四格表资料中我们比较的两个样本率的比较,因此对于所有率的差值大于原假设的极端情况,我们需要计算所有的概率累加,得到发生如此极端值的概率。

当四格表资料为配对设计时,该检验称为 Mc-Nemar Test, 检验两者阳性率是否一致,该值完全由两组中阳性的频数决定,则：

1. $\chi^2 = \frac{(b - c)^2}{b + c}, \upsilon = 1$

若 $b + c \le 40$, 则：

1. $\chi^2 = \frac{(|b-c|-1)^2}{b+c}, \upsilon = 1$

因为 Pearson $\chi^2$ 能反映实际频数和理论频数的的吻合程度,所以 $\chi^2$ 检验可以用作频数分布的拟合优度检验(goodness of fit test),用于判断样本是否符合正态分布,二项分布,Possion分布等。


## Rank  Based Test

用于总体分布未知,且观测变量为数值变量或者有序分类变量情况,需要关注的是不同的秩和检验的秩和 $T$ 是如何计算的以及遇到相等的数据该如何处理(只有数值变量会遇到相同的数据,对于观测变量为有序的等级数据,因为用的是其每一类结果的平均秩次,不存在该问题)。

### Wilcoxon Signed Rank Test for Paired Sample

依差值的绝对值从小到大编秩。编秩时遇到差值为 $0$ 的舍去不计,同时样本例数 $n - 1$ ; 遇到绝对值差值相等差数,符号相同则顺次编秩,符号相反则取平均秩次,再给秩次冠以原差值的正负号。分别计算出正负秩次 $T_+, T_-,$任取其中一个作为统计量秩和 $T$

1. $T \sim \mathcal{N}(\frac{n(n+1)}{4}, \frac{n(n+1)(2n+1)}{24}), \text{When } n > 25$
2. $Z = \frac{\mid T - n(n + 1)/4  \mid - 0.5}{\sqrt{n(n+1)(2n+1)/24}} \text{ 其中 0.5 为连续性校正常数。}$


当相同差值数较多时不(包括差值为0的值),校正式

$$Z = \frac{\left| T - \frac{n(n + 1)}{4} \right| - 0.5}{\sqrt{\frac{n(n+1)(2n+1)}{24} - \frac{\sum \left( t_j^3 - t_j \right)}{48}}}$$

其中, $t_j$ 是第 $j$ 个相同差值的个数。

### Wilcoxon Rank Sum Test/Mann Whitney Test for Independent Two Samples

1. 若观测变量为数值变量：将两组原始数据分别从小到大排队,再将两组数据由小到大统一编秩,若有同组相同数据则顺序编秩,若有不同组别相同数据则取平均秩次。记两组中样本例数较小的为 $n_1$ 其秩和为统计量 $T$ .
2. 若观测变量为有序的多分类变量：将每个观测单位按观测变量等级排序,则观测变量各个等级的平均秩次为该组观测单位秩次和的均值,则可求得每个分组的秩和,取观测单位数较小的组的秩和作为统计量 $T$.

则统计量 $T$:

1. $T \sim \mathcal{N}(\frac{n_1(N+1)}{2}, \frac{n_1n_2(N+1)}{12}), \text{where} N = n_1 + n_2$
1. $Z = \frac{|T - \frac{n_1(N+1)}{2}| - 0.5}{\sqrt{\frac{n_1n_2(N+1)}{12}}}$

当相同秩较多时,有如下校正：

1. $Z_c = Z\sqrt{C}, \text{where } C = 1 - \sum{(t_j^3 - t_j)}/(N^3 - N)$

### ANNOVA for Rank

单因素的方差分析对应Kruskal-Wallis Test, 随机区组设计的方差分析对应Freidman Test.


**Kruskal-Wallis Test**

构造 $H$ 统计量：假设有 $a$ 个组,第 $i$ 组的样本量 $n_i$ , $N$ 为各组样本量之和,将各组数据合并,编秩次,秩次相同的取平均值。 $R_{ij}$ 为第 $i$ 个组的第 $j$ 个个体的秩次, $\bar{R_i}$ 为第 $i$ 个组的平均秩次, $\bar{R}$ 为总平均秩次。

1. $H = \frac{\sum_{i}^{a}n_i(\bar{R_i} - \bar{R})^2}{\frac{1}{N - 1}\sum_{i=1}^a\sum_{j=1}^{n_i}(R_{ij} - \bar{R})^2}$ .

从上式可以看出 $H$ 统计量实际上是组间变异与总的变异的比值。

没有相同秩次时,秩次服从均匀分布, 上式可以简化为：

1. $H =\frac{12}{N(N + 1)}(\sum\frac{R_i^2}{n_i}) - 3(N+1)$ .

相同秩次过多时,上述以均匀分布为基础推导的公式需要进行校正：

1. $H_c = H/C$

其中 $C = 1 - \sum(t_j^3 - t_j) / (N^3 - N)$ .

$n_i$ 与 $a$ 较小时 直接计算或者查表。

$n$ 较大时,  $H$ 近似服从于 $\chi^2_{a-1}$ .


实际上也可以对数据编秩,然后用数据的秩次代替原数据进行方差分析得到 $F$ 统计量, $H$ 统计量与 $F$ 统计量有如下关系：

$F = \frac{H/(a-1)}{(N-1-H)/(N-a)}$

**Friedman Test**

在区组(行)内进行编秩,有相同的则取平均秩次。 $i$ 代表不同的区组, $j$ 代表不同地处理水平。

1. $M = \frac{\sum_{j=1}^{a}n(\bar{R}_j - \bar{R})^2}{\sum_{j=1}^{a}\sum_{i=1}^{n}(R_{ij} - \bar{R})^2 / n(a-1)}$

从上式可以看到 $M$ 统计量是处理水平之间的变异与总的变异的比值。


如果没有相同秩次时,上式可以简化为：

1. $M = \frac{12}{na(a + 1)}\sum_{j=1}^aR_j^2 - 3n(a+1)$

当相同秩过多时可以进行校正,校正系数为

1. $C = 1 - \sum_{j=1}^{a}\sum_{p=1}^{l_i}(t_{jp}^3 - t_{jp})/[na(a^2 -1 )]$

2. $M_c = M/C$


当 $n$ 以及 $a$ 较小时直接查表或精确计算。 $n$ 较大时 $M$ 近似服从于 $\chi^2_{a-1}$ .


同样地,我们也可以直接用编秩后数据代替原始数据的值进行随机区组设计的方差分析, 此时的 $F$ 统计量与 $M$ 统计量的关系如下：

1. $F = \frac{M/(a-1)}{(na-n - M)/(n-1)(a-1)}$ .

# Correlation ann Linear Regression

## Pearson/Spearman Correlation

考虑两个连续的正态分布变量 $X, Y$, 那么其样本的 Pearson 积差相关系数(product-moment correlation coefficient):

1. $r_p = \frac{\sum(X - \bar{X})(Y - \bar{Y})}{\sqrt{\sum{(X - \bar{X})^2} \sum{(Y - \bar{Y})^2}}}$
2. $t_r = \frac{r - 0}{S_r},  \upsilon = n -2 \text{ where } S_r = \sqrt{\frac{1-r^2}{n-2}}$

对于相关有如下注意的问题：

1. 分层数据合并假象,合并分层不改变其相关性时,才可以合并。
2. 两个变量应该都是随机的,而不是控制一个变量,观察另一个变量的结果。


对于非正态分布变量或者总体分布未知变量考虑使用 Spearman 等级相关(rank correlation)。将 $n$ 对观察值 $X_i, Y_i$ 由小到大编秩,则有：

1. $r_s = 1 - \frac{6\sum_{i=1}^{n}d_{i}^2}{n(n^2-1)}$
2. $t_r = \frac{r - 0}{S_r},  \upsilon = n -2 \text{ where } S_r = \sqrt{\frac{1-r^2}{n-2}} \text{ When } n \ge 20$

该简化公式适用于无相同秩次的情况。若存在相同秩次，应使用Pearson公式计算秩次的相关系数。

## Simple Linear Regression

简单线性回归,即只有一个自变量的线性回归,其回归方程形式如下：

1. $\hat{Y} = a + bX$
2. $b  = \frac{\sum{(X - \bar{X})(Y - \bar{Y})}}{\sum{(X - \bar{X})^2}}$, $a = \bar{Y} - b\bar{X}$

对参数 $b$ 有如下 $F$ 检验：

1. $F = \frac{MS_{\text{regression}}}{MS_{\text{residuals}}}, \upsilon_{\text{regression}} = 1, \upsilon_{\text{residuls}} = n - 2$


对参数 $b$ 同时有如下 $t$ 检验：

1. $t_b = \frac{b-0}{S_b}, \upsilon = n - 2 \text{ where } S_b = \frac{\sqrt{\frac{SS_{\text{residules}}}{n - 2}}}{\sqrt{\sum{(X - \bar{X})^2}}}$
2. $t_b \pm t_{\alpha, \upsilon}(S_b)$


对于拟合程度的判断可由决定系数确定：

1. $R^2 = \frac{SS_\text{regressiion}}{SS_{\text{total}}}$

对于拟合的回归方程,确定数值 $X_0$, 那么有：

1. $\mu_{Y|X_0} = \hat{Y_0} \pm t_{\alpha, \upsilon} S\sqrt{\frac{1}{n} + \frac{(X - X_0)^2}{\sum{(X-\bar{X})^2}}}$
2. $Y_0 = \hat{Y_0} \pm t_{\alpha, \upsilon}S\sqrt{1 + \frac{1}{n} + \frac{(X_0 - \bar{X})^2}{\sum{(X - \bar{X})^2}}}$

利用上面的第二个式子可以进行统计控制,即如果想要将 $Y$ 控制在一定范围,则可以通过控制 $X$ 将个体预测值控制在一定范围之中。

# 关于假设检验中若干问题

## 假设检验原理

求得样本统计量的分布,则可求得 $H_0$ 下样本统计量向假设的预期偏离如此大范围的机率,则依据小概率定律,选择拒绝或者接受原假设。

但是实际上要求得统计量的分布并不容易,对于参数统计,我们常常需要假设其分布,然后推理出相关统计量的分布；非参数统计则需要对其编秩,然后推断出秩和的分布。

## 假设检验与置信区间

对于 $t/z \space test$ 而言,统计量 $t/z$ 的大小表示为向均值偏离多少个标准差, 而置信区间的形式则为均值加上多少个标准差。

1. $t/z = \frac{\bar{x} - \mu_{\bar{x}}}{\sigma_{\bar{x}}}$
  
2. $\mu_{95\%} = \bar{x} \pm \frac{t}{z_{95\%}} \cdot \sigma_{\bar{x}}$

置信区间的含义在于用100个样本均值计算得到置信区间,其范围包括总体均值的个数为95,但是对个一个样本均值计算出来的区间,其是否包括该总体均值只有是或者不是,而不是有 95%的概率包括,因为该区间以及总体均值都是确定的值。

## I and II type error and power

$H_0$ 没有差异为阴性结果, $H_1$ 为具有差异,阳性结果。I 型错误是拒绝 $H_0$ 所犯的错误为 $\alpha$, II 型错误为不拒绝 $H_0$ 所犯的错误为 $\beta$, 其含义为在 $H_1$ 得到该统计量的概率, $1 - \beta$ 即为检验功效,即在 $H_1$ 为真的情况下,在指定的 $\alpha$ 检出其存在差异的概率,即敏感度(sensitivity).

## 统计量分布计算的Bootstrap以及置换检验

但是在实际的假设检验过程,倘若需要求得样本统计量的分布,往往需要知晓总体的概率分布。由此在假设检验过程之中,除了零假设以外,实际上在样本统计量的分布的计算之中,同时隐含了总体的分布以及方差齐性等假设,而这些假设也有对应的检验方法。因此,假设检验真正的概率应该所有假设概率的乘积,而不仅仅是在零假设之下所计算出的概率。因此，p值并非‘原假设为真的概率’，而是在原假设及所有其他模型假设（如正态性、方差齐性）均成立的前提下，获得当前或更极端观测结果的条件概率。对p值的这种误读是统计学中最常见的错误之一。以上所考虑的是一定要得到样本统计量的确切分布,进而得到精确的概率,例如正态总体假设下,方差齐性的 $t test$, 但是很多情况下我们不必得到样本统计量的精确分布,得到一个大概估计即可,例如大样本下的正态检验, $R\times C$ 列表值用卡方分布近似,非参数检验-秩检验等。在计算机时代,我们可以直接利用Bootstrp模拟得到假设之下样本统计量的分布。


## 假设检验与线性回归参数检验的等效性

许多参数检验方法都可以被看作是线性模型的特例。例如，两独立样本t检验在数学上等价于一个自变量为二分类虚拟变量（0/1）的简单线性回归。同样，方差分析（ANOVA）也等价于一个自变量为多个虚拟变量的多元线性回归。


- 两独立样本t检验 vs. 简单线性回归: 一个两独立样本t检验（如比较男性和女性的身高差异）在数学上等价于一个简单线性回归模型。在这个模型中，因变量是身高，自变量是一个虚拟编码的分类变量（如，男性=1，女性=0）。回归系数 b 的t检验结果与两独立样本t检验的结果是完全一样的。

- ANOVA vs. 多元线性回归: 单因素方差分析（ANOVA）等价于一个使用虚拟编码（dummy coding）的多元线性回归模型。F检验的结果是相同的。这揭示了ANOVA实际上是广义线性模型（General Linear Model）的一个特例。
